{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google\n",
      "  Downloading google-2.0.3-py2.py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from google) (4.9.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from beautifulsoup4->google) (2.0)\n",
      "Installing collected packages: google\n",
      "Successfully installed google-2.0.3\n",
      "Collecting git+https://github.com/adbar/trafilatura.git\n",
      "  Cloning https://github.com/adbar/trafilatura.git to /tmp/pip-req-build-bd1d6rpi\n",
      "  Running command git clone -q https://github.com/adbar/trafilatura.git /tmp/pip-req-build-bd1d6rpi\n",
      "Collecting htmldate>=0.6.2\n",
      "  Downloading htmldate-0.6.2-py3-none-any.whl (32 kB)\n",
      "Collecting justext>=2.2.0\n",
      "  Downloading jusText-2.2.0-py2.py3-none-any.whl (860 kB)\n",
      "\u001b[K     |████████████████████████████████| 860 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: readability-lxml>=0.7.1 in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from trafilatura==0.4.1) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: lxml>=4.4.2 in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from trafilatura==0.4.1) (4.5.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.22.0 in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from trafilatura==0.4.1) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.8.1 in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from htmldate>=0.6.2->trafilatura==0.4.1) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from readability-lxml>=0.7.1->trafilatura==0.4.1) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: cssselect in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from readability-lxml>=0.7.1->trafilatura==0.4.1) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/mike/.local/lib/python3.8/site-packages (from requests>=2.22.0->trafilatura==0.4.1) (2018.8.24)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from requests>=2.22.0->trafilatura==0.4.1) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from requests>=2.22.0->trafilatura==0.4.1) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from python-dateutil>=2.8.1->htmldate>=0.6.2->trafilatura==0.4.1) (1.14.0)\n",
      "Building wheels for collected packages: trafilatura\n",
      "  Building wheel for trafilatura (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for trafilatura: filename=trafilatura-0.4.1-py3-none-any.whl size=154799 sha256=5ef7ce3ca2cbf87e6f554e1626b3e401d9ab991928b00c0f8b07d7e09593c2f4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_xefl_3v/wheels/48/ed/70/138e35a5e7304fa89c2484d3c24a3e0320ac0713670cb03cb3\n",
      "Successfully built trafilatura\n",
      "Installing collected packages: htmldate, justext, trafilatura\n",
      "Successfully installed htmldate-0.6.2 justext-2.2.0 trafilatura-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google\n",
    "!pip install -U git+https://github.com/adbar/trafilatura.git\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import trafilatura\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.medicare.gov/medigap-supplemental-insurance-plans/\n",
      "https://www.investopedia.com/articles/personal-finance/071014/medigap-vs-medicare-advantage-which-better.asp\n",
      "https://www.investopedia.com/terms/m/medigap-insurance.asp\n",
      "https://www.cms.gov/Medicare/Health-Plans/Medigap\n",
      "https://www.medicareresources.org/medicare-benefits/medigap/\n",
      "https://www.mymedicarematters.org/coverage/medigap/\n",
      "https://www.aarp.org/health/medicare-qa-tool/what-is-medigap-insurance/\n",
      "https://www.medicareinteractive.org/get-answers/medicare-health-coverage-options/supplemental-insurance-for-original-medicare-medigaps/medigap-overview\n",
      "https://www.bcbs.com/medicare/medigap\n",
      "https://www.medicareinteractive.org/get-answers/medicare-health-coverage-options/supplemental-insurance-for-original-medicare-medigaps/comparing-medigap-options\n",
      "https://en.wikipedia.org/wiki/Medigap\n",
      "https://medicareadvocacy.org/medicare-info/medigap/\n",
      "https://www.thestreet.com/personal-finance/insurance/health-insurance/medigap-vs-medicare-advantage\n",
      "https://www.aarp.org/health/medicare-insurance/info-2017/choosing-right-medigap-plan.html\n",
      "https://www.fidelity.com/viewpoints/retirement/medigap-what-you-need-to-know\n",
      "https://www.medicare.gov/supplements-other-insurance\n",
      "https://www.medicare.gov/medigap-supplemental-insurance-plans/\n",
      "https://www.aarpmedicareplans.com/medicare-education/medicare-supplement-plans.html\n",
      "https://www.ehealthinsurance.com/medicare/supplement-all/medicare-supplement-plans\n",
      "https://www.ehealthinsurance.com/medicare/supplement-all/compare-medicare-supplement-plans\n",
      "https://www.humana.com/medicare/medicare-supplement-plans\n",
      "https://www.investopedia.com/articles/personal-finance/071014/medigap-vs-medicare-advantage-which-better.asp\n",
      "https://www.ehealthmedicare.com/medicare-supplement-articles/medicare-supplement-insurance-plans/\n",
      "https://www.anthem.com/medicare/medicare-supplement-plans/\n",
      "https://www.payingforseniorcare.com/best-medicare-supplement-plans\n",
      "https://www.medicareresources.org/medicare-benefits/medigap/\n",
      "https://www.ehealthmedicare.com/medicare-supplement-articles/how-much-does-a-medicare-supplement-plan-cost/\n",
      "https://www.bcbsm.com/medicare/help/faqs/works/supplement-plans-cover.html\n",
      "https://www.cms.gov/Medicare/Health-Plans/Medigap\n",
      "https://www.medicaremadeclear.com/basics/medicare-supplement-insurance-costs-and-coverage\n"
     ]
    }
   ],
   "source": [
    "uQuery_1 = \"Medigap\" # here is where everything begins: we choose two queries that we like to compare\n",
    "uQuery_2 = \"Medicare Supplement Insurance\"\n",
    "\n",
    "uNum = 15\n",
    "\n",
    "def getResults(uQuery, uTLD, uNum, uStart, uStop):\n",
    "  try: \n",
    "      from googlesearch import search \n",
    "  except ImportError:  \n",
    "      print(\"No module named 'google' found\") \n",
    "  \n",
    "  # What are we searching for \n",
    "  query = uQuery\n",
    "  \n",
    "  # Prepare the data frame to store urls\n",
    "  d = []\n",
    "\n",
    "  for j in search(query, tld=uTLD, num=uNum, start=uStart, stop=uStop, pause=2): \n",
    "      d.append(j)\n",
    "      print(j)\n",
    "  return d\n",
    "\n",
    "results_1 = getResults(uQuery_1, \"com\", uNum, 1,uNum)\n",
    "results_2 = getResults(uQuery_2, \"com\", uNum, 1,uNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of articles (before filtering)  28\n",
      "total number of articles saved on Medigap_MedicareSupplementInsurance.csv 28\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1) # make sure output is not truncated (cols width)\n",
    "pd.set_option(\"display.max_rows\", -1) # make sure output is not truncated (rows)\n",
    "\n",
    "def readResults(urls, query):\n",
    "    # Prepare the data frame to store results\n",
    "    x = []\n",
    "    position = 0 # position on the serp\n",
    "\n",
    "    # Loop items in results\n",
    "    for page in urls:\n",
    "       position += 1\n",
    "       downloaded = trafilatura.fetch_url(page)\n",
    "       if downloaded is not None: # assuming the download was successful\n",
    "        result = trafilatura.extract(downloaded, include_tables=False, include_formatting=False, include_comments=False) \n",
    "        x.append((page, result, query, position))\n",
    "    return x\n",
    "\n",
    "d = readResults(results_1, uQuery_1) # get results from there 1st query\n",
    "e = readResults(results_2, uQuery_2) # get results from there 2nd query\n",
    "\n",
    "df_1 = pd.DataFrame(d, columns=('url', 'result', 'query', 'position')) # store data in a data frame\n",
    "df_2 = pd.DataFrame(e, columns=('url', 'result', 'query', 'position')) # store data in a data frame\n",
    "\n",
    "df_final = pd.concat([df_1, df_2])\n",
    "print(\"total number of articles (before filtering) \",len(df_final))\n",
    "\n",
    "# Remove rows where result is empty \n",
    "df_final['result'].replace(' ', np.nan, inplace=True)\n",
    "df_final = df_final.dropna(subset=['result'])\n",
    "\n",
    "# Remove rows where article are less than 200 characters in lenght\n",
    "df_final = df_final[df_final['result'].apply(lambda x: len(str(x))>100)]\n",
    "\n",
    "\n",
    "# Reindex df\n",
    "df_final.index = range(len(df_final.index))\n",
    "\n",
    "# Set the file name\n",
    "uQuery = uQuery_1 + \"_\" + uQuery_2\n",
    "cleanQuery = re.sub('\\W+','', uQuery)\n",
    "file_name = cleanQuery + \".csv\"\n",
    "\n",
    "# Store data to CSV\n",
    "df_final.to_csv(file_name, encoding='utf-8', index=True)\n",
    "print(\"total number of articles saved on\",file_name, len(df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scattertext\n",
      "  Downloading scattertext-0.0.2.64-py3-none-any.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from scattertext) (1.4.1)\n",
      "Requirement already satisfied: pandas in /home/mike/.local/lib/python3.8/site-packages (from scattertext) (0.23.4)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.11.1-cp38-cp38-manylinux1_x86_64.whl (8.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.7 MB 30.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from scattertext) (1.18.4)\n",
      "Requirement already satisfied: six in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from scattertext) (1.14.0)\n",
      "Collecting mock\n",
      "  Downloading mock-4.0.2-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from scattertext) (0.22.2.post1)\n",
      "Requirement already satisfied: pytz>=2011k in /home/mike/.local/lib/python3.8/site-packages (from pandas->scattertext) (2018.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages (from pandas->scattertext) (2.8.1)\n",
      "Collecting patsy>=0.5\n",
      "  Downloading patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 48.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/mike/.local/lib/python3.8/site-packages (from scikit-learn->scattertext) (0.14.1)\n",
      "Installing collected packages: patsy, statsmodels, mock, scattertext\n",
      "Successfully installed mock-4.0.2 patsy-0.5.1 scattertext-0.0.2.64 statsmodels-0.11.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/.pyenv/versions/3.8.2/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting additional hourse power - adding more libraries\n",
    "!pip install scattertext\n",
    "\n",
    "%matplotlib inline\n",
    "import scattertext as st\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "import io\n",
    "from scipy.stats import rankdata, hmean, norm\n",
    "import spacy\n",
    "import os, pkgutil, json, urllib\n",
    "from urllib.request import urlopen\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "from scattertext import CorpusFromPandas, produce_scattertext_explorer\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "nlp = spacy.load('en') # make sure you have the right language here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['index'] = df_final.index\n",
    "df_final.groupby('query').apply(lambda x: x.result.apply(lambda x: len(x.split())).sum())\n",
    "df_final['parsed'] = df_final.result.apply(nlp) # run NER using spaCy\n",
    "\n",
    "# Turn it into a Scattertext corpus\n",
    "corpus = (st.CorpusFromParsedDocuments(df_final, \n",
    "                                       category_col='query', \n",
    "                                       parsed_col='parsed')\n",
    "          .build()\n",
    "          .remove_terms(ENGLISH_STOP_WORDS, ignore_absences=True)) # remove stop words in English  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
